{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRmfGnKhwa3-",
        "outputId": "d1486589-8c77-48ca-9253-46a5a5800f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "\n",
        "    # The book originally contained this unnecessary \"else\" clause:\n",
        "    #else:\n",
        "    #    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    #        text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUdEYBchwsrV",
        "outputId": "0455a175-0804-4681-b317-2cc05a1c9844"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Another example entry:\\n\", data[999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw0PZh3xwubs",
        "outputId": "0824f797-5437-4351-d165-affadf6bee50"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "  instruction_text = (\n",
        "      f\"Below is an instruction that describes a task. \"\n",
        "      f\"Write a response that appropriately completes the request. \"\n",
        "      f\"\\n\\n ### Instruction: \\n{entry['instruction']}\"\n",
        "  )\n",
        "\n",
        "  input_text = f\"\\n\\n ### Input: \\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "  return instruction_text + input_text"
      ],
      "metadata": {
        "id": "P7QTJUx6wwFt"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n ### Response: \\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9ICab4LyUKG",
        "outputId": "d1d22776-e810-4d81-c125-2ad5dcbab99f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
            "\n",
            " ### Instruction: \n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            " ### Input: \n",
            "Ocassion\n",
            "\n",
            " ### Response: \n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n ### Response: \\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ohQuupjyof9",
        "outputId": "135ce7d5-2bae-4925-acd6-fa30a073bcd8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
            "\n",
            " ### Instruction: \n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            " ### Response: \n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ],
      "metadata": {
        "id": "9uK253PHy61O"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05PMMK8UzCtk",
        "outputId": "5159ebec-73f3-4b47-f27c-9e403ef98658"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "  def __init__(self,data,tokenizer):\n",
        "    self.data = data\n",
        "\n",
        "    self.encoded_text = []\n",
        "    for entry in data:\n",
        "      instruction_plus_input = format_input(entry)\n",
        "      response_text = f\"\\n\\n ### Response: \\n{entry['output']}\"\n",
        "      full_text = instruction_plus_input + response_text\n",
        "      self.encoded_text.append(tokenizer.encode(full_text)) # Use tokenizer.encode() here\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.encoded_text[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "B35LaaNazQAM"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\",allowed_special= {\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC4ADu_00DWN",
        "outputId": "0ed894fd-0713-48af-877a-63c0ad84e4b6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to batch_max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ],
      "metadata": {
        "id": "YMDZxeJi0ZMM"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80ML8Niu28e3",
        "outputId": "c9380a9d-d8f0-4a00-95ec-ac3e99912e02"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "CiecsbZ12-VU"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "godwTagC3t89",
        "outputId": "4d64189d-9553-4f4d-aceb-47c9d6c41033"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "vvBOu9y73v2c"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs,targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6SwVRR95DX8",
        "outputId": "a8a9e9e2-839f-4391-8429-741b3aa23228"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_1 = torch.tensor(\n",
        "    [[-1.0,1.0],\n",
        "     [-0.5,1.5]]\n",
        ")\n",
        "\n",
        "targets_1 = torch.tensor([0,1])\n",
        "\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1,targets_1)\n",
        "print(loss_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw1GOdCm5Qd8",
        "outputId": "01e9acb8-f13c-43ec-c30b-84b2421d4839"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]]  # New 3rd training example\n",
        ")\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "\n",
        "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ6Mb8xP5m58",
        "outputId": "0922531b-61a8-42d6-909b-20cfc674e196"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "\n",
        "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)\n",
        "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg94BfHT5pkM",
        "outputId": "8a139f01-880b-4c46-a55f-cf6c4b8bfbbc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n",
            "loss_1 == loss_3: tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "nHjPlOQg5sgs"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd7-BU_Z51fM",
        "outputId": "d4963da5-58a4-4874-96c8-925d17102b16"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ],
      "metadata": {
        "id": "bIXRtxSE520U"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "WjXzoDUf54hk"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "egsjEdah56NM"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw9P-MB06JME",
        "outputId": "eb55a330-a1ad-476d-afa2-0021eb48d939"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(inputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sbbdUr36LID",
        "outputId": "3b39710b-f4ef-472b-ce05-48906f16bf17"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
            "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   220,   628,\n",
            "        44386, 46486,    25,   220,   198, 30003,  6525,   262,  6827,  1262,\n",
            "          257,   985,   576,    13,   628, 44386, 23412,    25,   220,   198,\n",
            "          464,  5156,   318,   845, 13779,    13,   628, 44386, 18261,    25,\n",
            "          220,   198,   464,  5156,   318,   355, 13779,   355,   257,  4936,\n",
            "           13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from previous_chapters import GPTModel, load_weights_into_gpt\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnFJPLaQ6Nm8",
        "outputId": "ebb3a6c8-0760-443d-b886-e992d39c4edf"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 81.1kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.42MiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 140kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [01:52<00:00, 12.6MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 15.1MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 2.42MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.63MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfSfVQyt6dLE",
        "outputId": "2adc37cc-2902-40ef-d563-48e0090a76a2"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
            "\n",
            " ### Instruction: \n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from previous_chapters import (\n",
        "    generate,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ],
      "metadata": {
        "id": "I5aoowKC691t"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx6TfXFy7C2U",
        "outputId": "cc202136-360d-41d9-a074-87b14eba4bae"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The active sentence is the sentence that is being processed. The passive sentence is the sentence that is being processed.\n",
            "The active sentence is the sentence that is being processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from previous_chapters import (\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")"
      ],
      "metadata": {
        "id": "hvQ4Fder7PPM"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaBfI3Ok7U0F",
        "outputId": "c8183660-bb90-4d8b-a0b9-a7ba26f9de33"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.8631935596466063\n",
            "Validation loss: 3.778960847854614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPJWl6bq7YO0",
        "outputId": "022d22ab-00df-4a8d-b1ed-3a15f1a943cd"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.853, Val loss 2.835\n",
            "Ep 1 (Step 000005): Train loss 1.163, Val loss 1.099\n",
            "Ep 1 (Step 000010): Train loss 0.845, Val loss 0.942\n",
            "Ep 1 (Step 000015): Train loss 0.846, Val loss 0.905\n",
            "Ep 1 (Step 000020): Train loss 0.769, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.755, Val loss 0.851\n",
            "Ep 1 (Step 000030): Train loss 0.789, Val loss 0.829\n",
            "Ep 1 (Step 000035): Train loss 0.708, Val loss 0.801\n",
            "Ep 1 (Step 000040): Train loss 0.662, Val loss 0.799\n",
            "Ep 1 (Step 000045): Train loss 0.622, Val loss 0.783\n",
            "Ep 1 (Step 000050): Train loss 0.659, Val loss 0.775\n",
            "Ep 1 (Step 000055): Train loss 0.745, Val loss 0.757\n",
            "Ep 1 (Step 000060): Train loss 0.701, Val loss 0.734\n",
            "Ep 1 (Step 000065): Train loss 0.632, Val loss 0.723\n",
            "Ep 1 (Step 000070): Train loss 0.523, Val loss 0.720\n",
            "Ep 1 (Step 000075): Train loss 0.562, Val loss 0.721\n",
            "Ep 1 (Step 000080): Train loss 0.590, Val loss 0.711\n",
            "Ep 1 (Step 000085): Train loss 0.501, Val loss 0.697\n",
            "Ep 1 (Step 000090): Train loss 0.543, Val loss 0.679\n",
            "Ep 1 (Step 000095): Train loss 0.493, Val loss 0.676\n",
            "Ep 1 (Step 000100): Train loss 0.494, Val loss 0.672\n",
            "Ep 1 (Step 000105): Train loss 0.555, Val loss 0.665\n",
            "Ep 1 (Step 000110): Train loss 0.544, Val loss 0.662\n",
            "Ep 1 (Step 000115): Train loss 0.502, Val loss 0.655\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.    ### Instruction:  Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response:  The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.   ### Instruction:  Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.427, Val loss 0.662\n",
            "Ep 2 (Step 000125): Train loss 0.442, Val loss 0.677\n",
            "Ep 2 (Step 000130): Train loss 0.440, Val loss 0.675\n",
            "Ep 2 (Step 000135): Train loss 0.402, Val loss 0.674\n",
            "Ep 2 (Step 000140): Train loss 0.406, Val loss 0.671\n",
            "Ep 2 (Step 000145): Train loss 0.364, Val loss 0.672\n",
            "Ep 2 (Step 000150): Train loss 0.378, Val loss 0.671\n",
            "Ep 2 (Step 000155): Train loss 0.406, Val loss 0.670\n",
            "Ep 2 (Step 000160): Train loss 0.405, Val loss 0.680\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.680\n",
            "Ep 2 (Step 000170): Train loss 0.320, Val loss 0.682\n",
            "Ep 2 (Step 000175): Train loss 0.332, Val loss 0.676\n",
            "Ep 2 (Step 000180): Train loss 0.390, Val loss 0.658\n",
            "Ep 2 (Step 000185): Train loss 0.411, Val loss 0.656\n",
            "Ep 2 (Step 000190): Train loss 0.339, Val loss 0.643\n",
            "Ep 2 (Step 000195): Train loss 0.326, Val loss 0.626\n",
            "Ep 2 (Step 000200): Train loss 0.303, Val loss 0.626\n",
            "Ep 2 (Step 000205): Train loss 0.345, Val loss 0.622\n",
            "Ep 2 (Step 000210): Train loss 0.361, Val loss 0.622\n",
            "Ep 2 (Step 000215): Train loss 0.390, Val loss 0.625\n",
            "Ep 2 (Step 000220): Train loss 0.298, Val loss 0.637\n",
            "Ep 2 (Step 000225): Train loss 0.332, Val loss 0.650\n",
            "Ep 2 (Step 000230): Train loss 0.287, Val loss 0.641\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.    ### Instruction:  Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response:  The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.   ### Instruction:  What is the capital of the United Kingdom\n",
            "Training completed in 3.22 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from previous_chapters import plot_losses\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "MqcvAUQv7gPk",
        "outputId": "3ba7559a-4981-4ece-b30c-253b35e7ae3b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "  input_text = format_input(entry)\n",
        "\n",
        "  token_ids = generate(\n",
        "      model = model,\n",
        "      idx = text_to_token_ids(input_text,tokenizer).to(device),\n",
        "      max_new_tokens = 256,\n",
        "      context_size = BASE_CONFIG['context_length'],\n",
        "      eos_id = 50256\n",
        "  )\n",
        "  generated_text = token_ids_to_text(token_ids,tokenizer)\n",
        "  response_text  = (\n",
        "      generated_text[len(input_text):]\n",
        "      .replace(\"### Response: \", \"\")\n",
        "      .strip()\n",
        "  )\n",
        "\n",
        "  print(input_text)\n",
        "  print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "  print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "  print(\"-------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7pP7jrZ9Mxl",
        "outputId": "c1130e2e-a24b-4211-fbb0-b1583b5d014b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
            "\n",
            " ### Instruction: \n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            " ### Input: \n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a cheetah.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
            "\n",
            " ### Instruction: \n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> A thunderstorm is a type of cumulus cloud that is formed when thunderstorms produce a dense, fast-moving, and intense updraft that causes the surface of the cloud to rise rapidly.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
            "\n",
            " ### Instruction: \n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtYsvKb99-iN",
        "outputId": "54e9a41a-b2b8-4c82-abb1-9cbabdb6834d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [01:14<00:00,  1.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhdjk5IV_w8U",
        "outputId": "ab6ebb17-4d29-410a-fa8e-b13cd69fc7e0"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxwMz8-6_1Iy",
        "outputId": "6ff279d7-6696-4ca2-8815-6363c4e15a9b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mboOfpwr_1Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cS38n1Ls_1D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaAmixrz_1BO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}