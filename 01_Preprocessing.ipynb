{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Stemming"
      ],
      "metadata": {
        "id": "ForQUgC4uXeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siZFO8tbucy5",
        "outputId": "be4819e2-8bf9-45d7-cb5b-5c829b8a24c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "YICiwhRLuo3N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemmer.stem(\"cat\"))\n",
        "print(stemmer.stem(\"cats\"))\n",
        "\n",
        "print(stemmer.stem(\"running\"))\n",
        "print(stemmer.stem(\"runs\"))\n",
        "\n",
        "print(stemmer.stem(\"better\"))\n",
        "print(stemmer.stem(\"achieve\"))\n",
        "\n",
        "print(stemmer.stem(\"cricket\"))\n",
        "print(stemmer.stem(\"cricketer\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjU5hv6-usAX",
        "outputId": "c94318ff-4bdc-4347-ff1e-4b671838051d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "cat\n",
            "run\n",
            "run\n",
            "better\n",
            "achiev\n",
            "cricket\n",
            "cricket\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The cats are sleeping. What are the dogs doing\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "tokens_stemmed = [stemmer.stem(token) for token in tokens]\n",
        "print(tokens_stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iSDb9gWvLNJ",
        "outputId": "63c3173c-065d-4070-b41c-e1c150ffcee5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'cat', 'are', 'sleep', '.', 'what', 'are', 'the', 'dog', 'do']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization"
      ],
      "metadata": {
        "id": "CfGPRdGmvcJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averages_perceptron_tagger')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heiodVF-vtF3",
        "outputId": "07bb11e6-2f10-4f74-b0a4-e6f121a3e768"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Error loading averages_perceptron_tagger: Package\n",
            "[nltk_data]     'averages_perceptron_tagger' not found in index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(lemmatizer.lemmatize(\"achieve\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjJfpLFMvtCd",
        "outputId": "ce40474e-1a5b-4cea-bcba-82e6813c0873"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "achieve\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stopwords"
      ],
      "metadata": {
        "id": "Ao8JzLLlvs_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvKaf99Svs8I",
        "outputId": "2df97d5d-59c0-4bd2-a16b-e657c6620fe6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_stopwords = stopwords.words('english')\n",
        "print(f\"There are {len(english_stopwords)} stopwords in English\")\n",
        "print(english_stopwords[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_ewVGstvs4_",
        "outputId": "114e8147-6bad-4a29-8aad-048ad1b5554f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 198 stopwords in English\n",
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###POS tagging"
      ],
      "metadata": {
        "id": "Qx6XBO4ZyupN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TwrR0-qyy_0",
        "outputId": "99c9b680-91f7-4df5-8a24-1d6b84fe8ae0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = word_tokenize(\"They refuse to go\")\n",
        "print(nltk.pos_tag(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ0elsNGy8wT",
        "outputId": "81707845-ed15-4b06-b19d-cba13fdeb8c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('go', 'VB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = word_tokenize(\"We need the refuse permit\")\n",
        "print(nltk.pos_tag(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaiKklT3zGlK",
        "outputId": "aa6cbdb5-a04e-493d-c172-9307a62bf72c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('We', 'PRP'), ('need', 'VBP'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HfsHxB18zNr8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}